{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dOQ-2xS_MYHi"
   },
   "source": [
    "## **1. Import the necessary libraries**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2266,
     "status": "ok",
     "timestamp": 1598792498000,
     "user": {
      "displayName": "GRP18 ISS",
      "photoUrl": "",
      "userId": "03799563883876230975"
     },
     "user_tz": -480
    },
    "id": "yoi4gWDELtek",
    "outputId": "2fc1ab3a-6b1f-49c4-c4f1-70d8103abe0d"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-41fb026d3bbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os, pathlib\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "model_folderpath = os.path.abspath(os.getcwd())\n",
    "folderpath = pathlib.Path(model_folderpath).parent\n",
    "data_folderpath = os.path.join(folderpath, 'Data')\n",
    "\n",
    "print(folderpath)\n",
    "print(model_folderpath)\n",
    "print(data_folderpath)\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"---\")\n",
    "print(\"tensorflow: \", tf.__version__)\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0amhwjZ4M2m-"
   },
   "source": [
    "## **2. Create a function to plot image without axis**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1493,
     "status": "ok",
     "timestamp": 1598792501244,
     "user": {
      "displayName": "GRP18 ISS",
      "photoUrl": "",
      "userId": "03799563883876230975"
     },
     "user_tz": -480
    },
    "id": "OFxsBB1mNXl2",
    "outputId": "9ca008b3-77b2-464b-c2e0-c414f4666f32"
   },
   "outputs": [],
   "source": [
    "def implt(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "print(implt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3N41iixORPz"
   },
   "source": [
    "## **3. Set matplotlib to have seaborn plot style**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2438,
     "status": "ok",
     "timestamp": 1598784984379,
     "user": {
      "displayName": "GRP18 ISS",
      "photoUrl": "",
      "userId": "03799563883876230975"
     },
     "user_tz": -480
    },
    "id": "OyO5OsUrOYNQ",
    "outputId": "4a1526a1-aa2e-4d29-eb40-6724227ba363"
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= True\n",
    "plt.rcParams['ytick.left']      = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "print(\"Matplotlib setup completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5w2jAiKZOmgP"
   },
   "source": [
    "## **4. Prepare image data for training and testing**\n",
    "---\n",
    "URL: https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "* Step 1: Set model parameters\n",
    "* Setp 2: Create a dataset (with/without generator for data augumentation)\n",
    "* Step 2: Print the class names\n",
    "* Step 3: Retrieve the row size and the column size of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1015,
     "status": "error",
     "timestamp": 1598788589959,
     "user": {
      "displayName": "GRP18 ISS",
      "photoUrl": "",
      "userId": "03799563883876230975"
     },
     "user_tz": -480
    },
    "id": "v3Ad2V0pO1TX",
    "outputId": "43cf01de-b9f2-42d2-9c58-ed8dbf2560bd"
   },
   "outputs": [],
   "source": [
    "                                                                                # Step 1\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "seed = 42\n",
    "validation_split = 0.2\n",
    "\n",
    "                                                                                # Step 2\n",
    "#Dataset with Generator (Need to check that validation dataset has no duplicates with training dataset)\n",
    "#trDatagen = ImageDataGenerator(\n",
    "#    rescale=1./255,\n",
    "#    width_shift_range=0.1,\n",
    "#    height_shift_range=0.1,\n",
    "#    rotation_range=20,\n",
    "#    horizontal_flip=True,\n",
    "#    vertical_flip=False,\n",
    "#    validation_split=validation_split)\n",
    "\n",
    "#tsDatagen = ImageDataGenerator(\n",
    "#    rescale=1./255, \n",
    "#    validation_split=validation_split)\n",
    "\n",
    "#trDataset = trDatagen.flow_from_directory(\n",
    "#    data_folderpath,\n",
    "#    target_size=(img_height, img_width),\n",
    "#    color_mode=\"rgb\",\n",
    "#    classes=None,\n",
    "#    class_mode=\"categorical\",\n",
    "#    batch_size=batch_size,\n",
    "#    shuffle=True,\n",
    "#    seed=seed,\n",
    "#    subset='training')\n",
    "\n",
    "#tsDataset = tsDatagen.flow_from_directory(\n",
    "#    data_folderpath,\n",
    "#    target_size=(img_height, img_width),\n",
    "#    color_mode=\"rgb\",\n",
    "#    classes=None,\n",
    "#    class_mode=\"categorical\",\n",
    "#    batch_size=batch_size,\n",
    "#    shuffle=True,\n",
    "#    seed=seed,\n",
    "#    subset='validation')\n",
    "\n",
    "#Dataset without Generator (stable datastream)\n",
    "trDataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_folderpath,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "tsDataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_folderpath,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "                                                                                # Step 3\n",
    "class_names = trDataset.class_names\n",
    "print(f\"Class labels are {class_names}\")\n",
    "\n",
    "                                                                                # Step 4\n",
    "for image_batch, label_batch in trDataset:\n",
    "    print(f\"The shape of Training Data Batch is  {image_batch.shape}\")\n",
    "    print(f\"The shape of Training Label Batch is  {label_batch.shape}\")\n",
    "    plt.imshow((image_batch[0].numpy()).astype(np.uint8))\n",
    "    break\n",
    "\n",
    "for image_batch, label_batch in tsDataset:\n",
    "    print(f\"The shape of Testing Data Batch is  {image_batch.shape}\")\n",
    "    print(f\"The shape of Testing Label Batch is  {label_batch.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DoP3WcoJW-jZ"
   },
   "source": [
    "## 5. Define the model\n",
    "___\n",
    "* Step 1: Setup the optimizer to be used for training\n",
    "* Step 2: Set a name for the coming model (required for saving)\n",
    "* Step 3: Define the number of classes\n",
    "* Step 4: Define the convolutional neural network model (to be completed)\n",
    "* Step 5: Create models for training and testing\n",
    "* Step 6: Display the summary of the model of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0HMOes0kXCPd",
    "outputId": "b60eee9e-ddb4-41a7-ae29-adad1de6c30f"
   },
   "outputs": [],
   "source": [
    "                                                                                # Step 1\n",
    "learning_rate = 0.001\n",
    "optmz       = optimizers.RMSprop(lr=learning_rate)\n",
    "\n",
    "                                                                                # Step 2\n",
    "modelname   = 'Food_Classification'\n",
    "\n",
    "                                                                                # Step 3\n",
    "num_classes = 3\n",
    "\n",
    "                                                                                # Step 4\n",
    "def createModel():\n",
    "    \n",
    "    xin = Input(shape=(256,256,3))\n",
    "    x = Rescaling(1./255) (xin)\n",
    "    \n",
    "    x = Conv2D(64,(3,3),activation=None, padding='same')(x)\n",
    "    x = Activation('relu') (x)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(2,2)) (x)\n",
    "\n",
    "    x = Conv2D(32,(3,3),activation=None, padding='same')(x)\n",
    "    x = BatchNormalization() (x)\n",
    "    x = Activation('relu') (x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(2,2)) (x)\n",
    "    x = Conv2D(32,(3,3),activation=None, padding='same')(x)    \n",
    "    x = Activation('relu') (x)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(2,2)) (x)\n",
    "    x = Conv2D(64,(3,3),activation=None, padding='same')(x)\n",
    "    x = BatchNormalization() (x)   \n",
    "    x = Activation('relu') (x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(2,2)) (x)\n",
    "    x = Conv2D(128,(3,3),activation=None, padding='same')(x)    \n",
    "    x = BatchNormalization() (x)       \n",
    "    x = Activation('relu') (x)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(2,2)) (x)\n",
    "    x = Flatten() (x)\n",
    "    x = Dense(64, activation='relu') (x)\n",
    "    x = Dropout(0.5) (x)\n",
    "    x = Dense(num_classes, activation='softmax') (x)\n",
    "\n",
    "\n",
    "    model = Model(inputs=xin,outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optmz, \n",
    "                  metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "                                                                                # Step 4\n",
    "model       = createModel() # This is meant for training\n",
    "modelGo     = createModel() # This is used for final testing\n",
    "\n",
    "model.summary()                                                                 # Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlquJEaFZxV9"
   },
   "source": [
    "## **6. Create the checkpoints to be applied during training**\n",
    "---\n",
    "* Step 1: Create a checkpoint to save the model from an epoch when validation accuracy is the highest\n",
    "* Step 2: Create a checkpoint to save the training loss, training accuracy, validation loss and validation accuracy of each epoch into a csv file\n",
    "* Step 3: Put the two checkpoint objects into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "9-a1LSCbahKy",
    "outputId": "9af55551-1667-4c5e-dc2c-1efb3f700988"
   },
   "outputs": [],
   "source": [
    "                                                                                # Step 1\n",
    "modelpath        = model_folderpath + '/' + modelname + \".hdf5\"\n",
    "logpath         = model_folderpath + '/' + modelname +'.csv'\n",
    "checkpoint      = ModelCheckpoint(modelpath, \n",
    "                                  monitor='val_categorical_accuracy', \n",
    "                                  verbose=0, \n",
    "                                  save_best_only=True, \n",
    "                                  mode='max')\n",
    "\n",
    "                                                                                # Step 2\n",
    "csv_logger      = CSVLogger(logpath)\n",
    "\n",
    "                                                                                # Step 3\n",
    "def lrSchedule(epoch):\n",
    "    lr = learning_rate\n",
    "    \n",
    "    if epoch >= 45:\n",
    "        lr *= 0.005\n",
    "    elif epoch >= 35:\n",
    "        lr *= 0.01\n",
    "    elif epoch >= 25:\n",
    "        lr *= 0.1\n",
    "\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    return lr \n",
    "\n",
    "LRScheduler = LearningRateScheduler(lrSchedule) \n",
    "\n",
    "                                                                               # Step 4\n",
    "callbacks_list  = [checkpoint, csv_logger, LRScheduler]\n",
    "\n",
    "print(\"Callbacks created:\")\n",
    "print(callbacks_list[0])\n",
    "print(callbacks_list[1])\n",
    "print(callbacks_list[2])\n",
    "print('')\n",
    "print(\"Path to model:\", modelpath)\n",
    "print(\"Path to log:  \", logpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mKgjQsmfOBz"
   },
   "source": [
    "## **7. Train the deep learning model**\n",
    "___\n",
    "URL: https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "23lUNwpGfV0A",
    "outputId": "c2317079-3448-4769-957a-9cd4e1655987"
   },
   "outputs": [],
   "source": [
    "model.fit(trDataset,                        # Training dataset\n",
    "          validation_data=tsDataset,        # Validation data and label\n",
    "          epochs=100,                       # The amount of epochs to be trained                  \n",
    "          shuffle=True,                     # To shuffle the training data\n",
    "          callbacks=callbacks_list)         # Callbacks to execute the checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TevfJTd-s0nk"
   },
   "source": [
    "## **8. Validate the deep learning model**\n",
    "---\n",
    "* Step 1: Set a list of image and labels for the test dataset \n",
    "* Step 2: Load the trained weights and compile the model\n",
    "* Step 3: Make prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2sVtWmcVtiV5",
    "outputId": "b9015ac2-5cff-419c-e899-629432fd8219"
   },
   "outputs": [],
   "source": [
    "                                                                                # Step 1\n",
    "tsimages = []\n",
    "tslabels = []\n",
    "for image_batch, label_batch in tsDataset:\n",
    "    for i in range(len(label_batch)):\n",
    "        tsimages.append(image_batch[i].numpy())\n",
    "        tslabels.append(label_batch[i].numpy())\n",
    "\n",
    "tsimages = np.array(tsimages)\n",
    "        \n",
    "print(np.shape(tsimages))\n",
    "print(np.shape(tslabels))\n",
    "print(len(tsimages))\n",
    "print(len(tslabels))\n",
    "\n",
    "plt.imshow(tsimages[0].astype(np.uint8))\n",
    "print(class_names)\n",
    "print(tslabels[0])\n",
    "\n",
    "                                                                                # Step 2\n",
    "modelGo.load_weights(modelpath)\n",
    "modelGo.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optmz,\n",
    "                metrics=['categorical_accuracy'])\n",
    "\n",
    "                                                                                # Step 3\n",
    "predicts    = modelGo.predict(tsimages)\n",
    "print(\"Prediction completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0aOCUljp5qq4"
   },
   "source": [
    "## **9. Report classification metrics**\n",
    "---\n",
    "* Step 1: Convert label from one-hot to integer\n",
    "* Step 2: Obtain the class labels from the test dataset\n",
    "* Step 3: Calculate the accuracy score\n",
    "* Step 4: Generate classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "2tI4hBmk5uRh",
    "outputId": "c23d5880-faf6-47e3-bc06-0c04f22730ce"
   },
   "outputs": [],
   "source": [
    "                                                                                # Step 1\n",
    "predout     = np.argmax(predicts,axis=1)\n",
    "\n",
    "                                                                                # Step 2\n",
    "testout     = np.argmax(tslabels, axis=1)\n",
    "\n",
    "                                                                                # Step 3\n",
    "testScores  = metrics.accuracy_score(testout, predout)                           \n",
    "\n",
    "                                                                                # Step 4\n",
    "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n",
    "print(metrics.classification_report(testout,\n",
    "                                    predout,\n",
    "                                    target_names=class_names,\n",
    "                                    digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gEK_4UXN6IVa"
   },
   "source": [
    "## **10. Print confusion matrix**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "UCBJCYp26L1t",
    "outputId": "a9a61aa7-1a1a-4246-b45d-148de3c9c06f"
   },
   "outputs": [],
   "source": [
    "confusion   = metrics.confusion_matrix(testout,predout)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QMIDPD46UGT"
   },
   "source": [
    "## **11. Plot curves on validation loss and accuracy**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "qr2ZbvUi6YHf",
    "outputId": "e1aed820-1228-46f2-9212-9b83b687e9bd"
   },
   "outputs": [],
   "source": [
    "records     = pd.read_csv(logpath)\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'], label=\"validation\")\n",
    "plt.plot(records['loss'],label=\"training\")\n",
    "plt.yticks([0.00,0.50,1.00,1.50])\n",
    "plt.title('Loss value',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['categorical_accuracy'],label=\"validation\")\n",
    "plt.plot(records['categorical_accuracy'],label=\"training\")\n",
    "plt.yticks([0.5,0.6,0.7,0.8])\n",
    "plt.title('Accuracy',fontsize=12)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWoTz-bLug3X"
   },
   "source": [
    "## **12. Save the model plot**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tz1YfuV1ujcE",
    "outputId": "555bdc4f-85e7-4f63-876c-a4621927f4c7"
   },
   "outputs": [],
   "source": [
    "plotpath  = model_folderpath + '/' + modelname + '_plot.png'\n",
    "plot_model(model, \n",
    "           to_file=plotpath, \n",
    "           show_shapes=True, \n",
    "           show_layer_names=False,\n",
    "           rankdir='TB')\n",
    "\n",
    "print(\"Path to plot:\", plotpath)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Food_Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
